{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "def parse_colabfold_results(output_text):\n",
    "   # parse the colabfold output\n",
    "   results = []\n",
    "   \n",
    "   # find lines with results - go through each line\n",
    "   lines = output_text.split('\\n')\n",
    "   current_job = None\n",
    "   current_metrics = {}\n",
    "   \n",
    "   for line in lines:\n",
    "       line = line.strip()\n",
    "       \n",
    "       # get job name\n",
    "       if 'Processing' in line:\n",
    "           current_job = line.split('Processing ')[1].split('...')[0]\n",
    "           current_metrics = {}\n",
    "           \n",
    "       # get the metrics\n",
    "       elif 'mean_plddt' in line and 'max_ptm' in line and 'max_iptm' in line:\n",
    "           # extract numbers manually\n",
    "           plddt_part = line.split(\"'mean_plddt': \")[1].split(',')[0]\n",
    "           ptm_part = line.split(\"'max_ptm': \")[1].split(',')[0] \n",
    "           iptm_part = line.split(\"'max_iptm': \")[1].split('}')[0]\n",
    "           \n",
    "           current_metrics['mean_plddt'] = float(plddt_part)\n",
    "           current_metrics['max_ptm'] = float(ptm_part)\n",
    "           current_metrics['max_iptm'] = float(iptm_part)\n",
    "           \n",
    "       # get binding score\n",
    "       elif 'Binding score:' in line:\n",
    "           score_part = line.split('Binding score: ')[1]\n",
    "           current_metrics['binding_score'] = float(score_part)\n",
    "           \n",
    "           # now we have everything for this job\n",
    "           if current_job and len(current_metrics) == 4:\n",
    "               job_name = current_job\n",
    "               mean_plddt = current_metrics['mean_plddt']\n",
    "               max_ptm = current_metrics['max_ptm']\n",
    "               max_iptm = current_metrics['max_iptm'] \n",
    "               binding_score = current_metrics['binding_score']\n",
    "               \n",
    "               # get nanobody and antigen names from job name\n",
    "               parts = job_name.split('_')\n",
    "               nanobody = parts[0] + '_' + parts[1]  # like nbGFP_6xzf\n",
    "               antigen = parts[2]  # like GFP\n",
    "               \n",
    "               result = {\n",
    "                   'job_name': job_name,\n",
    "                   'nanobody': nanobody,\n",
    "                   'antigen': antigen,\n",
    "                   'mean_plddt': mean_plddt,\n",
    "                   'max_ptm': max_ptm,\n",
    "                   'max_iptm': max_iptm,\n",
    "                   'binding_score': binding_score\n",
    "               }\n",
    "               results.append(result)\n",
    "   \n",
    "   return pd.DataFrame(results)\n",
    "\n",
    "def load_multiple_seed_files(base_filename, seeds=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]):\n",
    "    # Load and combine results from multiple seed files\n",
    "    all_results = []\n",
    "    \n",
    "    for seed in seeds:\n",
    "        # Generate filename for this seed\n",
    "        seed_filename = base_filename.replace('.txt', f'_seed_{seed}.txt')\n",
    "        \n",
    "        try:\n",
    "            # Try to read the file\n",
    "            try:\n",
    "                with open(seed_filename, 'r', encoding='utf-8') as file:\n",
    "                    file_content = file.read()\n",
    "            except UnicodeDecodeError:\n",
    "                with open(seed_filename, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "                    file_content = file.read()\n",
    "            \n",
    "            # Parse this seed's results\n",
    "            seed_df = parse_colabfold_results(file_content)\n",
    "            \n",
    "            if len(seed_df) > 0:\n",
    "                # Add seed information\n",
    "                seed_df['seed'] = seed\n",
    "                all_results.append(seed_df)\n",
    "                print(f\"Loaded {len(seed_df)} results from seed {seed}\")\n",
    "            else:\n",
    "                print(f\"No results found in {seed_filename}\")\n",
    "                \n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {seed_filename}\")\n",
    "            continue\n",
    "    \n",
    "    if all_results:\n",
    "        # Combine all seeds\n",
    "        combined_df = pd.concat(all_results, ignore_index=True)\n",
    "        print(f\"Total combined results: {len(combined_df)} experiments across {len(all_results)} seeds\")\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"No seed files found!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def calculate_cross_seed_statistics(df):\n",
    "    # Calculate mean and std across seeds for each nanobody-antigen pair\n",
    "    \n",
    "    # Group by nanobody-antigen combination and calculate statistics\n",
    "    grouped = df.groupby(['nanobody', 'antigen']).agg({\n",
    "        'mean_plddt': ['mean', 'std', 'count'],\n",
    "        'max_ptm': ['mean', 'std', 'count'], \n",
    "        'max_iptm': ['mean', 'std', 'count'],\n",
    "        'binding_score': ['mean', 'std', 'count']\n",
    "    }).round(3)\n",
    "    \n",
    "    # Flatten column names\n",
    "    grouped.columns = ['_'.join(col).strip() for col in grouped.columns]\n",
    "    grouped = grouped.reset_index()\n",
    "    \n",
    "    # Add quality flags based on mean values\n",
    "    grouped['high_confidence'] = (grouped['max_iptm_mean'] > 0.7) & (grouped['max_ptm_mean'] > 0.7)\n",
    "    grouped['good_interface'] = grouped['max_iptm_mean'] > 0.5\n",
    "    grouped['good_structure'] = grouped['mean_plddt_mean'] > 80\n",
    "    \n",
    "    # Fill NaN std values with 0 (happens when only 1 seed available)\n",
    "    std_columns = [col for col in grouped.columns if '_std' in col]\n",
    "    grouped[std_columns] = grouped[std_columns].fillna(0)\n",
    "    \n",
    "    return grouped\n",
    "\n",
    "def create_binding_matrix_visualization_multiseed(df_stats, score_column='binding_score_mean', \n",
    "                                                 std_column='binding_score_std', \n",
    "                                                 title_suffix='AlphaFold2 Multimer Score Multi-Seed'):\n",
    "    # Create visualization with mean +/- std from multiple seeds\n",
    "    \n",
    "    if len(df_stats) == 0:\n",
    "        print(\"No data to plot\")\n",
    "        return None\n",
    "        \n",
    "    # Sort the names alphabetically (case insensitive)\n",
    "    nanobodies = sorted(df_stats['nanobody'].unique(), key=str.lower)\n",
    "    antigens = sorted(df_stats['antigen'].unique(), key=str.lower)\n",
    "    \n",
    "    # Make pivot tables for mean and std\n",
    "    df_clean = df_stats.drop_duplicates(subset=['nanobody', 'antigen'], keep='first')\n",
    "    \n",
    "    mean_matrix = df_clean.pivot(index='nanobody', columns='antigen', values=score_column)\n",
    "    mean_matrix = mean_matrix.reindex(index=nanobodies, columns=antigens)\n",
    "    \n",
    "    std_matrix = df_clean.pivot(index='nanobody', columns='antigen', values=std_column)\n",
    "    std_matrix = std_matrix.reindex(index=nanobodies, columns=antigens)\n",
    "    \n",
    "    # Create count matrix to show how many seeds contributed\n",
    "    count_matrix = df_clean.pivot(index='nanobody', columns='antigen', values=score_column.replace('_mean', '_count'))\n",
    "    count_matrix = count_matrix.reindex(index=nanobodies, columns=antigens)\n",
    "    \n",
    "    # Make the plot bigger\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    \n",
    "    # Use viridis colormap \n",
    "    cmap = 'viridis'\n",
    "    \n",
    "    # Create annotation labels with mean +/- std\n",
    "    annot_labels = mean_matrix.round(3).astype(str) + '\\n+/-' + std_matrix.round(3).astype(str)\n",
    "    \n",
    "    # Add seed count information where helpful\n",
    "    for i in range(len(nanobodies)):\n",
    "        for j in range(len(antigens)):\n",
    "            if not pd.isna(count_matrix.iloc[i, j]) and count_matrix.iloc[i, j] < 3:\n",
    "                # Show count if less than 3 seeds\n",
    "                current_label = annot_labels.iloc[i, j]\n",
    "                seed_count = int(count_matrix.iloc[i, j])\n",
    "                annot_labels.iloc[i, j] = f\"{current_label}\\n(n={seed_count})\"\n",
    "\n",
    "    ax = sns.heatmap(\n",
    "       mean_matrix,\n",
    "       annot=annot_labels,\n",
    "       fmt='',\n",
    "       cmap=cmap,\n",
    "       square=True,\n",
    "       linewidths=0.5,\n",
    "       cbar_kws={'label': f'{title_suffix}'},\n",
    "       annot_kws={'size': 14}  # smaller font to fit multiple lines\n",
    "    )\n",
    "    \n",
    "    # Make colorbar label bigger\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.set_label(f'{title_suffix}', size=20)\n",
    "    \n",
    "    # Highlight the diagonal - these should be the real binding pairs\n",
    "    for i in range(min(len(nanobodies), len(antigens))):\n",
    "        ax.add_patch(plt.Rectangle((i, i), 1, 1, fill=False, edgecolor='red', lw=5))\n",
    "    \n",
    "    plt.title(f'Nanobody-Antigen Binding Matrix ({title_suffix})', fontsize=22, pad=20)\n",
    "    plt.xlabel('Antigens', fontsize=22)\n",
    "    plt.ylabel('Nanobodies', fontsize=22)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=18)\n",
    "    plt.yticks(rotation=0, fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save with descriptive filename\n",
    "    plt.savefig(\"binding_matrix_alphafold2_multimer_multiseed.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return mean_matrix, std_matrix\n",
    "\n",
    "def analyze_multiseed_results(df_raw, df_stats):\n",
    "    # Analyze multi-seed ColabFold results\n",
    "    print(\"=== AlphaFold2 Multimer Multi-Seed Results Analysis ===\")\n",
    "    print()\n",
    "    \n",
    "    if len(df_raw) == 0:\n",
    "        print(\"ERROR: No data found - check file format\")\n",
    "        return\n",
    "    \n",
    "    # Basic statistics\n",
    "    n_seeds = df_raw['seed'].nunique()\n",
    "    n_combinations = len(df_stats)\n",
    "    \n",
    "    print(f\"Seeds analyzed: {sorted(df_raw['seed'].unique())}\")\n",
    "    print(f\"Total experiments: {len(df_raw)}\")\n",
    "    print(f\"Unique nanobody-antigen combinations: {n_combinations}\")\n",
    "    print(f\"Number of nanobodies: {df_stats['nanobody'].nunique()}\")\n",
    "    print(f\"Number of antigens: {df_stats['antigen'].nunique()}\")\n",
    "    print()\n",
    "    \n",
    "    # Show completeness - how many combinations have all seeds\n",
    "    complete_combinations = (df_stats['binding_score_count'] == n_seeds).sum()\n",
    "    print(f\"Combinations with all {n_seeds} seeds: {complete_combinations}/{n_combinations}\")\n",
    "    \n",
    "    # Show seed distribution\n",
    "    seed_counts = df_stats['binding_score_count'].value_counts().sort_index()\n",
    "    print(\"Seed count distribution:\")\n",
    "    for count, freq in seed_counts.items():\n",
    "        print(f\"  {int(count)} seeds: {freq} combinations\")\n",
    "    print()\n",
    "    \n",
    "    # Quality check on mean values\n",
    "    high_conf_count = df_stats['high_confidence'].sum()\n",
    "    good_interface_count = df_stats['good_interface'].sum() \n",
    "    good_structure_count = df_stats['good_structure'].sum()\n",
    "    \n",
    "    print(\"Quality check (based on mean across seeds):\")\n",
    "    print(f\"  High confidence (ipTM>0.7, pTM>0.7): {high_conf_count}/{n_combinations}\")\n",
    "    print(f\"  Good interface (ipTM>0.5): {good_interface_count}/{n_combinations}\")\n",
    "    print(f\"  Good structure (pLDDT>80): {good_structure_count}/{n_combinations}\")\n",
    "    print()\n",
    "    \n",
    "    # Top binding pairs by mean score\n",
    "    print(\"Top 5 binding pairs (highest mean binding score):\")\n",
    "    top_pairs = df_stats.nlargest(5, 'binding_score_mean')\n",
    "    for _, row in top_pairs.iterrows():\n",
    "        confidence_flag = \"high_conf\" if row['high_confidence'] else \"low_conf \"\n",
    "        print(f\"  {confidence_flag} {row['nanobody']} + {row['antigen']}: \"\n",
    "              f\"{row['binding_score_mean']:.3f}+/-{row['binding_score_std']:.3f} \"\n",
    "              f\"(ipTM: {row['max_iptm_mean']:.3f}+/-{row['max_iptm_std']:.3f}, \"\n",
    "              f\"pTM: {row['max_ptm_mean']:.3f}+/-{row['max_ptm_std']:.3f}, n={int(row['binding_score_count'])})\")\n",
    "    print()\n",
    "    \n",
    "    # Check diagonal pairs\n",
    "    diagonal_pairs = []\n",
    "    for _, row in df_stats.iterrows():\n",
    "        nb_clean = row['nanobody'].replace('nb', '').split('_')[0].upper()\n",
    "        ag_clean = row['antigen'].upper()\n",
    "        if nb_clean == ag_clean:\n",
    "            diagonal_pairs.append(row)\n",
    "    \n",
    "    if diagonal_pairs:\n",
    "        print(\"Expected binding pairs (diagonal matches):\")\n",
    "        for _, pair in pd.DataFrame(diagonal_pairs).iterrows():\n",
    "            confidence_flag = \"high_conf\" if pair['high_confidence'] else \"low_conf \"\n",
    "            print(f\"  {confidence_flag} {pair['nanobody']} + {pair['antigen']}: \"\n",
    "                  f\"{pair['binding_score_mean']:.3f}+/-{pair['binding_score_std']:.3f} \"\n",
    "                  f\"(ipTM: {pair['max_iptm_mean']:.3f}+/-{pair['max_iptm_std']:.3f}, \"\n",
    "                  f\"pTM: {pair['max_ptm_mean']:.3f}+/-{pair['max_ptm_std']:.3f}, n={int(pair['binding_score_count'])})\")\n",
    "        print()\n",
    "    \n",
    "    # Summary statistics across all experiments\n",
    "    print(\"Summary statistics (across all seeds):\")\n",
    "    print(f\"  Binding Score - Mean: {df_raw['binding_score'].mean():.3f} \"\n",
    "          f\"Std: {df_raw['binding_score'].std():.3f} \"\n",
    "          f\"Range: {df_raw['binding_score'].min():.3f} to {df_raw['binding_score'].max():.3f}\")\n",
    "    print(f\"  ipTM - Mean: {df_raw['max_iptm'].mean():.3f} \"\n",
    "          f\"Std: {df_raw['max_iptm'].std():.3f} \"\n",
    "          f\"Range: {df_raw['max_iptm'].min():.3f} to {df_raw['max_iptm'].max():.3f}\")\n",
    "    print(f\"  pTM - Mean: {df_raw['max_ptm'].mean():.3f} \"\n",
    "          f\"Std: {df_raw['max_ptm'].std():.3f} \"\n",
    "          f\"Range: {df_raw['max_ptm'].min():.3f} to {df_raw['max_ptm'].max():.3f}\")\n",
    "    print(f\"  pLDDT - Mean: {df_raw['mean_plddt'].mean():.1f} \"\n",
    "          f\"Std: {df_raw['mean_plddt'].std():.1f} \"\n",
    "          f\"Range: {df_raw['mean_plddt'].min():.1f} to {df_raw['mean_plddt'].max():.1f}\")\n",
    "\n",
    "# Run the multi-seed analysis\n",
    "if __name__ == \"__main__\":\n",
    "    # Base filename - will look for _seed_0.txt, _seed_1.txt, _seed_2.txt versions\n",
    "    base_filename = \"alphafold2_multimer_v3_combined_information.txt\"\n",
    "    seeds_to_analyze = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    \n",
    "    print(\"=== Loading Multi-Seed AlphaFold2 Multimer Results ===\")\n",
    "    print(f\"Looking for files: {base_filename.replace('.txt', '_seed_X.txt')}\")\n",
    "    print()\n",
    "    \n",
    "    # Load all seed files\n",
    "    df_raw = load_multiple_seed_files(base_filename, seeds_to_analyze)\n",
    "    \n",
    "    if len(df_raw) > 0:\n",
    "        # Calculate statistics across seeds\n",
    "        df_stats = calculate_cross_seed_statistics(df_raw)\n",
    "        \n",
    "        print(f\"Calculated statistics for {len(df_stats)} unique combinations\")\n",
    "        print()\n",
    "        \n",
    "        # Create visualizations\n",
    "        print(\"Creating visualization...\")\n",
    "        mean_matrix, std_matrix = create_binding_matrix_visualization_multiseed(\n",
    "            df_stats, 'binding_score_mean', 'binding_score_std'\n",
    "        )\n",
    "        \n",
    "        # Analyze results\n",
    "        analyze_multiseed_results(df_raw, df_stats)\n",
    "        \n",
    "        # Save results\n",
    "        df_raw.to_csv('alphafold2_results_all_seeds.csv', index=False)\n",
    "        df_stats.to_csv('alphafold2_results_statistics.csv', index=False)\n",
    "        if mean_matrix is not None:\n",
    "            mean_matrix.to_csv('alphafold2_binding_matrix_mean.csv')\n",
    "            std_matrix.to_csv('alphafold2_binding_matrix_std.csv')\n",
    "        \n",
    "        print()\n",
    "        print(\"=== Files Saved ===\")\n",
    "        print(\"alphafold2_results_all_seeds.csv - Raw data from all seeds\")\n",
    "        print(\"alphafold2_results_statistics.csv - Mean+/-Std statistics\")\n",
    "        print(\"alphafold2_binding_matrix_mean.csv - Mean binding matrix\")\n",
    "        print(\"alphafold2_binding_matrix_std.csv - Std deviation matrix\")\n",
    "        print(\"binding_matrix_alphafold2_multimer_multiseed.png - Visualization\")\n",
    "        \n",
    "    else:\n",
    "        print(\"No data found - check that seed files exist!\")\n",
    "        print(f\"Expected files like: {base_filename.replace('.txt', '_seed_0.txt')}\")\n",
    "    \n",
    "    print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
