{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def parse_colabfold_results(output_text):\n",
    "   # parse the colabfold output\n",
    "   results = []\n",
    "   \n",
    "   # find lines with results - go through each line\n",
    "   lines = output_text.split('\\n')\n",
    "   current_job = None\n",
    "   current_metrics = {}\n",
    "   \n",
    "   for line in lines:\n",
    "       line = line.strip()\n",
    "       \n",
    "       # get job name\n",
    "       if '▶ Processing' in line:\n",
    "           current_job = line.split('▶ Processing ')[1].split('...')[0]\n",
    "           current_metrics = {}\n",
    "           \n",
    "       # get the metrics\n",
    "       elif 'mean_plddt' in line and 'max_ptm' in line and 'max_iptm' in line:\n",
    "           # extract numbers manually\n",
    "           plddt_part = line.split(\"'mean_plddt': \")[1].split(',')[0]\n",
    "           ptm_part = line.split(\"'max_ptm': \")[1].split(',')[0] \n",
    "           iptm_part = line.split(\"'max_iptm': \")[1].split('}')[0]\n",
    "           \n",
    "           current_metrics['mean_plddt'] = float(plddt_part)\n",
    "           current_metrics['max_ptm'] = float(ptm_part)\n",
    "           current_metrics['max_iptm'] = float(iptm_part)\n",
    "           \n",
    "       # get binding score\n",
    "       elif 'Binding score:' in line:\n",
    "           score_part = line.split('Binding score: ')[1]\n",
    "           current_metrics['binding_score'] = float(score_part)\n",
    "           \n",
    "           # now we have everything for this job\n",
    "           if current_job and len(current_metrics) == 4:\n",
    "               job_name = current_job\n",
    "               mean_plddt = current_metrics['mean_plddt']\n",
    "               max_ptm = current_metrics['max_ptm']\n",
    "               max_iptm = current_metrics['max_iptm'] \n",
    "               binding_score = current_metrics['binding_score']\n",
    "               \n",
    "               # get nanobody and antigen names from job name\n",
    "               parts = job_name.split('_')\n",
    "               nanobody = parts[0] + '_' + parts[1]  # like nbGFP_6xzf\n",
    "               antigen = parts[2]  # like GFP\n",
    "               \n",
    "               result = {\n",
    "                   'job_name': job_name,\n",
    "                   'nanobody': nanobody,\n",
    "                   'antigen': antigen,\n",
    "                   'mean_plddt': mean_plddt,\n",
    "                   'max_ptm': max_ptm,\n",
    "                   'max_iptm': max_iptm,\n",
    "                   'binding_score': binding_score\n",
    "               }\n",
    "               results.append(result)\n",
    "   \n",
    "   return pd.DataFrame(results)\n",
    "\n",
    "def filter_and_rank_colabfold_results(df):\n",
    "    \"\"\"Add quality checks for ColabFold results\"\"\"\n",
    "    # Quality flags based on confidence thresholds\n",
    "    df['high_confidence'] = (df['max_iptm'] > 0.7) & (df['max_ptm'] > 0.7)\n",
    "    df['good_interface'] = df['max_iptm'] > 0.5\n",
    "    df['good_structure'] = df['mean_plddt'] > 80\n",
    "    \n",
    "    # Rank by binding score - higher is better\n",
    "    df = df.sort_values('binding_score', ascending=False)\n",
    "    df['rank'] = range(1, len(df) + 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_binding_matrix_visualization(df, score_column='binding_score', title_suffix='AlphaFold2 Multimer Score'):\n",
    "    if len(df) == 0:\n",
    "        print(\"No data to plot\")\n",
    "        return None\n",
    "        \n",
    "    # Sort the names alphabetically (case insensitive)\n",
    "    nanobodies = sorted(df['nanobody'].unique(), key=str.lower)\n",
    "    antigens = sorted(df['antigen'].unique(), key=str.lower)\n",
    "    df = df.copy()\n",
    "    # Make pivot table\n",
    "    df = df.drop_duplicates(subset=['nanobody', 'antigen'], keep='first')\n",
    "    matrix = df.pivot(index='nanobody', columns='antigen', values=score_column)\n",
    "    matrix = matrix.reindex(index=nanobodies, columns=antigens)\n",
    "    \n",
    "    # Make the plot bigger\n",
    "    plt.figure(figsize=(14, 12))\n",
    "    \n",
    "    # Use YlOrRd colormap like HADDOCK analysis (higher scores = better for AlphaFold)\n",
    "    cmap = 'viridis'\n",
    "    \n",
    "    # get standard deviation from multiple metrics for error estimate\n",
    "    df['score_std'] = ((df['max_iptm'] - df['max_iptm'].mean())**2 + \n",
    "                     (df['max_ptm'] - df['max_ptm'].mean())**2 + \n",
    "                     (df['mean_plddt']/100 - (df['mean_plddt']/100).mean())**2)**0.5\n",
    "\n",
    "    std_matrix = df.pivot(index='nanobody', columns='antigen', values='score_std')\n",
    "    std_matrix = std_matrix.reindex(index=nanobodies, columns=antigens)\n",
    "\n",
    "    # Create annotation labels with score ± std\n",
    "    annot_labels = matrix.round(3).astype(str) + '\\n±' + std_matrix.round(3).astype(str)\n",
    "\n",
    "    ax = sns.heatmap(\n",
    "       matrix,\n",
    "       annot=annot_labels,\n",
    "       fmt='',\n",
    "       cmap=cmap,\n",
    "       square=True,\n",
    "       linewidths=0.5,\n",
    "       cbar_kws={'label': f'{title_suffix}'},\n",
    "       annot_kws={'size': 16}  # smaller font to fit both lines\n",
    "    )\n",
    "    \n",
    "    # Make colorbar label bigger\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.set_label(f'{title_suffix}', size=20)\n",
    "    \n",
    "    # Highlight the diagonal - these should be the real binding pairs\n",
    "    for i in range(min(len(nanobodies), len(antigens))):\n",
    "        ax.add_patch(plt.Rectangle((i, i), 1, 1, fill=False, edgecolor='red', lw=5))\n",
    "    \n",
    "    plt.title(f'Nanobody-Antigen Binding Matrix ({title_suffix})', fontsize=22, pad=20)\n",
    "    plt.xlabel('Antigens', fontsize=22)\n",
    "    plt.ylabel('Nanobodies', fontsize=22)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=18)\n",
    "    plt.yticks(rotation=0, fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"binding_matrix_alphafold2_multimer.png\", dpi=300)\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "def analyze_colabfold_results(df):\n",
    "    \"\"\"Analyze ColabFold results with HADDOCK-like output format\"\"\"\n",
    "    print(\"=== AlphaFold2 Multimer Results Analysis ===\")\n",
    "    print()\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        print(\"ERROR: No data found - check file format\")\n",
    "        return\n",
    "    \n",
    "    print(\"Total experiments:\", len(df))\n",
    "    print(\"Number of nanobodies:\", df['nanobody'].nunique())\n",
    "    print(\"Number of antigens:\", df['antigen'].nunique())\n",
    "    print()\n",
    "    \n",
    "    # Check quality of results\n",
    "    high_conf_count = df['high_confidence'].sum()\n",
    "    good_interface_count = df['good_interface'].sum()\n",
    "    good_structure_count = df['good_structure'].sum()\n",
    "    \n",
    "    print(\"Quality check:\")\n",
    "    print(\"  High confidence (ipTM>0.7, pTM>0.7):\", str(high_conf_count) + \"/\" + str(len(df)))\n",
    "    print(\"  Good interface (ipTM>0.5):\", str(good_interface_count) + \"/\" + str(len(df)))\n",
    "    print(\"  Good structure (pLDDT>80):\", str(good_structure_count) + \"/\" + str(len(df)))\n",
    "    print()\n",
    "    \n",
    "    # Best binding pairs based on binding score\n",
    "    print(\"Top 5 binding pairs (highest confidence score):\")\n",
    "    top_pairs = df.nlargest(5, 'binding_score')\n",
    "    for _, row in top_pairs.iterrows():\n",
    "        if row['high_confidence']:\n",
    "            flag = \"high_conf\"\n",
    "        else:\n",
    "            flag = \"low_conf \"\n",
    "        print(\"  \" + flag + \" \" + row['nanobody'] + \" + \" + row['antigen'] + \": \" + str(round(row['binding_score'], 3)) + \n",
    "              \" (ipTM: \" + str(round(row['max_iptm'], 3)) + \", pTM: \" + str(round(row['max_ptm'], 3)) + \")\")\n",
    "    print()\n",
    "    \n",
    "    # Check diagonal pairs - these should be the correct matches\n",
    "    diagonal_pairs = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Clean up names to check if they match\n",
    "        # Extract base name from nanobody (remove nb prefix and PDB ID)\n",
    "        nb_clean = row['nanobody'].replace('nb', '').split('_')[0].upper()\n",
    "        ag_clean = row['antigen'].upper()\n",
    "        if nb_clean == ag_clean:\n",
    "            diagonal_pairs.append(row)\n",
    "    \n",
    "    if diagonal_pairs:\n",
    "        print(\"Expected binding pairs (diagonal matches):\")\n",
    "        for pair in diagonal_pairs:\n",
    "            if pair['high_confidence']:\n",
    "                flag = \"high_conf\"\n",
    "            else:\n",
    "                flag = \"low_conf \"\n",
    "            print(\"  \" + flag + \" \" + pair['nanobody'] + \" + \" + pair['antigen'] + \": \" + str(round(pair['binding_score'], 3)) + \n",
    "                  \" (ipTM: \" + str(round(pair['max_iptm'], 3)) + \", pTM: \" + str(round(pair['max_ptm'], 3)) + \")\")\n",
    "        print()\n",
    "    \n",
    "    # Basic stats\n",
    "    print(\"Summary statistics:\")\n",
    "    print(\"  Binding Score - Mean:\", round(df['binding_score'].mean(), 3), \n",
    "          \"Std:\", round(df['binding_score'].std(), 3), \n",
    "          \"Range:\", round(df['binding_score'].min(), 3), \"to\", round(df['binding_score'].max(), 3))\n",
    "    print(\"  ipTM - Mean:\", round(df['max_iptm'].mean(), 3), \n",
    "          \"Std:\", round(df['max_iptm'].std(), 3), \n",
    "          \"Range:\", round(df['max_iptm'].min(), 3), \"to\", round(df['max_iptm'].max(), 3))\n",
    "    print(\"  pTM - Mean:\", round(df['max_ptm'].mean(), 3), \n",
    "          \"Range:\", round(df['max_ptm'].min(), 3), \"to\", round(df['max_ptm'].max(), 3))\n",
    "    print(\"  pLDDT - Mean:\", round(df['mean_plddt'].mean(), 1), \n",
    "          \"Range:\", round(df['mean_plddt'].min(), 1), \"to\", round(df['mean_plddt'].max(), 1))\n",
    "\n",
    "# Run the analysis\n",
    "if __name__ == \"__main__\":\n",
    "    # Change this path to your file\n",
    "    filename = \"alphafold2_multimer_v3_combined_information.txt\"\n",
    "    \n",
    "    # Fix encoding issue by specifying UTF-8\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            file_content = file.read()\n",
    "    except UnicodeDecodeError:\n",
    "        # Fallback to utf-8 with error handling\n",
    "        with open(filename, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            file_content = file.read()\n",
    "    except FileNotFoundError:\n",
    "        # If file doesn't exist, you can paste the content directly here\n",
    "        print(f\"File not found: {filename}\")\n",
    "        print(\"Please paste your ColabFold output below or update the filename\")\n",
    "        file_content = \"\"\n",
    "    \n",
    "    # Parse the file\n",
    "    df = parse_colabfold_results(file_content)\n",
    "    \n",
    "    if len(df) > 0:\n",
    "        df = filter_and_rank_colabfold_results(df)\n",
    "        \n",
    "        # Make the heatmap\n",
    "        matrix = create_binding_matrix_visualization(df, 'binding_score')\n",
    "        \n",
    "        # Print results\n",
    "        analyze_colabfold_results(df)\n",
    "        \n",
    "        # Save to csv files\n",
    "        df.to_csv('alphafold2_results.csv', index=False)\n",
    "        if matrix is not None:\n",
    "            matrix.to_csv('alphafold2_binding_matrix.csv')\n",
    "    else:\n",
    "        print(\"No data found - check file format\")\n",
    "    \n",
    "    print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
