{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4yBrceuFbf3"
      },
      "source": [
        "#ColabFold v1.5.5: AlphaFold2 w/ MMseqs2 BATCH\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/sokrypton/ColabFold/main/.github/ColabFold_Marv_Logo_Small.png\" height=\"256\" align=\"right\" style=\"height:256px\">\n",
        "\n",
        "Modified easy to use AlphaFold2 protein structure [(Jumper et al. 2021)](https://www.nature.com/articles/s41586-021-03819-2) and complex [(Evans et al. 2021)](https://www.biorxiv.org/content/10.1101/2021.10.04.463034v1) prediction using multiple sequence alignments generated through MMseqs2. For details, refer to our manuscript:\n",
        "\n",
        "[Mirdita M, Sch√ºtze K, Moriwaki Y, Heo L, Ovchinnikov S, Steinegger M. ColabFold: Making protein folding accessible to all.\n",
        "*Nature Methods*, 2022](https://www.nature.com/articles/s41592-022-01488-1)\n",
        "\n",
        "**Usage**\n",
        "\n",
        "`input_dir` directory with only fasta files or MSAs stored in Google Drive. MSAs need to be A3M formatted and have an `.a3m` extention. For MSAs MMseqs2 will not be called.\n",
        "\n",
        "`result_dir` results will be written to the result directory in Google Drive\n",
        "\n",
        "Old versions: [v1.4](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.4.0/batch/AlphaFold2_batch.ipynb), [v1.5.1](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.5.1/batch/AlphaFold2_batch.ipynb), [v1.5.2](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.5.2/batch/AlphaFold2_batch.ipynb), [v1.5.3-patch](https://colab.research.google.com/github/sokrypton/ColabFold/blob/56c72044c7d51a311ca99b953a71e552fdc042e1/batch/AlphaFold2_batch.ipynb)\n",
        "\n",
        "<strong>For more details, see <a href=\"#Instructions\">bottom</a> of the notebook and checkout the [ColabFold GitHub](https://github.com/sokrypton/ColabFold). </strong>\n",
        "This notebook was adapted to automatically run and visualize a binding prediction specificity experiment.\n",
        "-----------\n",
        "\n",
        "### News\n",
        "- <b><font color='green'>2023/07/31: The ColabFold MSA server is back to normal. It was using older DB (UniRef30 2202/PDB70 220313) from 27th ~8:30 AM CEST to 31st ~11:10 AM CEST.</font></b>\n",
        "- <b><font color='green'>2023/06/12: New databases! UniRef30 updated to 2023_02 and PDB to 230517. We now use PDB100 instead of PDB70 (see notes in the [main](https://colabfold.com) notebook).</font></b>\n",
        "- <b><font color='green'>2023/06/12: We introduced a new default pairing strategy: Previously, for multimer predictions with more than 2 chains, we only pair if all sequences taxonomically match (\"complete\" pairing). The new default \"greedy\" strategy pairs any taxonomically matching subsets.</font></b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wD8geeL9LSQP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "import shutil\n",
        "from typing import Dict, List, Tuple\n",
        "import warnings\n",
        "import tqdm\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# Define nanobody sequences with metadata\n",
        "nanobody_data = {\n",
        "    # 'nbGFP_6xzf': {\n",
        "    #    'sequence': 'QVQLVESGGALVQPGGSLRLSCAASGFPVNRYSMRWYRQADTNNDGWIEGDELKEREWVAGMSSAGDRSSYEDSVKGRFTISRDDARNTVYLQMNSLKPEDTAVYYCNVNVGFEYWGQGTQVTVSS',\n",
        "    #     'known_target': 'GFP',\n",
        "    #     'pdb_id': '6xzf'\n",
        "    # },\n",
        "    # 'nbmCherry_8ilx': {\n",
        "    #     'sequence': 'QVQLVQSGGGLVQAGGSLRLSCAASGRTFSDIAVGWFRQTPGKEREFVAAISWSGLIINYGDSVEDRFTISRDNAKSAVYLQMNSLKPEDTAVYYCAARIGMNYYYAREIEYPYWGQGTQVTVSK',\n",
        "    #     'known_target': 'mCherry',\n",
        "    #     'pdb_id': '8ilx'\n",
        "    # },\n",
        "    # 'nbSARS_7f5h': {\n",
        "    #     'sequence': 'QVQLQESGGGLVQAGGSLRLSCAASGSDFSSSTMGWYRQAPGKQREFVAISSEGSTSYAGSVKGRFTISRDNAKNTVYLQMNSLEPEDTAVYYCNVVDRWYDYWGQGTQVTVSA',\n",
        "    #     'known_target': 'SARS-Cov2-rbc',\n",
        "    #     'pdb_id': '7f5h'\n",
        "    # },\n",
        "    # 'nblys_1mel': {\n",
        "    #     'sequence': 'DVQLQASGGGSVQAGGSLRLSCAASGYTIGPYCMGWFRQAPGKEREGVAAINMGGGITYYADSVKGRFTISQDNAKNTVYLLMNSLEPEDTAIYYCAADSTIYASYYECGHGLSTGGYGYDSWGQGTQVTVSS',\n",
        "    #     'known_target': 'Lysozyme',\n",
        "    #     'pdb_id': '1mel'\n",
        "    # },\n",
        "    # 'nbALB_8y9t': {\n",
        "    #     'sequence': 'EVQLQESGGGLVQPGGSLRLSCAASGFTFSRYWMFWVRQAPGKGLEWISDINSGGTYTRYADSVKGRFTISRDNAKNTLYLQMNSLRAEDTAVYYCATNSGDGKRYCSGGYCYRSRGQGTLVTVSS',\n",
        "    #     'known_target': 'Albumin',\n",
        "    #   'pdb_id': '8y9t'\n",
        "    # },\n",
        "    'nbNAT_8zoy': {\n",
        "        'sequence': 'EVQLVESGGGLVQAGGSLRLSCAASGFPVTNFEMYWYRQAPGKEREWVAAIYSTGITEYADSVKGRFTISRDNSKNTVYLQMNSLKPEDTAVYYCNVKDNGAWRQNYDYWGQGTQVTVSS',\n",
        "        'known_target': 'NAT',\n",
        "        'pdb_id': '8zoy'\n",
        "    },\n",
        "}\n",
        "\n",
        "# Define antigen sequences with metadata\n",
        "antigen_data = {\n",
        "    'GFP': {\n",
        "        'sequence': 'VSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLTYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITLGMDELYK',\n",
        "        'uniprot': 'P42212'\n",
        "    },\n",
        "    'mCherry': {\n",
        "        'sequence': 'GMVSKGEEDNMAIIKEFMRFKVHMEGSVNGHEFEIEGEGEGRPYEGTQTAKLKVTKGGPLPFAWDILSPQFMYGSKAYVKHPADIPDYLKLSFPEGFKWERVMNFEDGGVVTVTQDSSLQDGEFIYKVKLRGTNFPSDGPVMQKKTMGWEASSERMYPEDGALKGEIKQRLKLKDGGHYDAEVKTTYKAKKPVQLPGAYNVNIKLDITSHNEDYTIVEQYERAEGRHSTGGMDELYK',\n",
        "        'uniprot': '-'\n",
        "    },\n",
        "    'SARS-Cov2-rbc': {\n",
        "        'sequence': 'AGSPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTGTLEVLFQ',\n",
        "        'uniprot': '-'\n",
        "    },\n",
        "    'Lysozyme': {\n",
        "        'sequence': 'KVFGRCELAAAMKRHGLDNYRGYSLGNWVCAAKFESNFNTQATNRNTDGSTDYGILQINSRWWCNDGRTPGSRNLCNIPCSALLSSDITASVNCAKKIVSDGNGMNAWVAWRNRCKGTDVQAWIRGCRL',\n",
        "        'uniprot': '-'\n",
        "    },\n",
        "    'Albumin': {\n",
        "        'sequence': 'RGVFRRDAHKSEVAHRFKDLGEENFKALVLIAFAQYLQQCPFEDHVKLVNEVTEFAKTCVADESAENCDKSLHTLFGDKLCTVATLRETYGEMADCCAKQEPERNECFLQHKDDNPNLPRLVRPEVDVMCTAFHDNEETFLKKYLYEIARRHPYFYAPELLFFAKRYKAAFTECCQAADKAACLLPKLDELRDEGKASSAKQRLKCASLQKFGERAFKAWAVARLSQRFPKAEFAEVSKLVTDLTKVHTECCHGDLLECADDRADLAKYICENQDSISSKLKECCEKPLLEKSHCIAEVENDEMPADLPSLAADFVESKDVCKNYAEAKDVFLGMFLYEYARRHPDYSVVLLLRLAKTYETTLEKCCAAADPHECYAKVFDEFKPLVEEPQNLIKQNCELFEQLGEYKFQNALLVRYTKKVPQVSTPTLVEVSRNLGKVGSKCCKHPEAKRMPCAEDYLSVVLNQLCVLHEKTPVSDRVTKCCTESLVNRRPCFSALEVDETYVPKEFNAETFTFHADICTLSEKERQIKKQTALVELVKHKPKATKEQLKAVMDDFAAFVEKCCKADDKETCFAEEGKKLVAASQAALGL',\n",
        "        'uniprot': '-'\n",
        "    },\n",
        "    'NAT': {\n",
        "        'sequence': 'APRDGDAQPRETWGKKIDFLLSVVGFAVDLANVWRFPYLCYKNGGGAFLIPYTLFLIIAGMPLFYMELALGQYNREGAATVWKICPFFKGVGYAVILIALYVGFYYNVIIAWSLYYLFSSFTLNLPWTDCGHTWNSPNCTDPKLLNGSVLGNHTKYSKYKFTPAAEFYERGVLHLHESSGIHDIGLPQWQLLLCLMVVVIVLYFSLWKGVKTSGKVVWITATLPYFVLFVLLVHGVTLPGASNGINAYLHIDFYRLKEATVWIDAATQIFFSLGAGFGVLIAFASYNKFDNNCYRDALLTSSINCITSFVSGFAIFSILGYMAHEHKVNIEDVATEGAGLVFILYPEAISTLSGSTFWAVVFFVMLLALGLDSSMGGMEAVITGLADDFQVLKRHRKLFTFGVTFSTFLLALFCITKGGIYVLTLLDTFAAGTSILFAVLMEAIGVSWFYGVDRFSNDIQQMMGFRPGLYWRLCWKFVSPAFLLFVVVVSIINFKPLTYDDYIFPPWANWVGWGIALSSMVLVPIYVIYKFLSTQGSLWERLAYGITPENEHHLVAQRDIRQFQLQHWLAI',\n",
        "        'uniprot': '-'\n",
        "    }\n",
        "\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kOblAo-xetgx"
      },
      "outputs": [],
      "source": [
        "#@title Input protein sequence, then hit `Runtime` -> `Run all`\n",
        "\n",
        "input_dir = '/content/input_fasta' #@param {type:\"string\"}\n",
        "result_dir = '/content/result' #@param {type:\"string\"}\n",
        "\n",
        "# number of models to use\n",
        "#@markdown ---\n",
        "#@markdown ### Advanced settings\n",
        "msa_mode = \"MMseqs2 (UniRef+Environmental)\" #@param [\"MMseqs2 (UniRef+Environmental)\", \"MMseqs2 (UniRef only)\",\"single_sequence\",\"custom\"]\n",
        "num_models = 5 #@param [1,2,3,4,5] {type:\"raw\"}\n",
        "num_recycles = 48 #@param [1,3,6,12,24,48] {type:\"raw\"}\n",
        "stop_at_score = 100 #@param {type:\"string\"}\n",
        "#@markdown - early stop computing models once score > threshold (avg. plddt for \"structures\" and ptmscore for \"complexes\")\n",
        "use_custom_msa = False\n",
        "num_relax = 5 #@param [0, 1, 5] {type:\"raw\"}\n",
        "use_amber = num_relax > 0\n",
        "relax_max_iterations = 200 #@param [0,200,2000] {type:\"raw\"}\n",
        "use_templates = False #@param {type:\"boolean\"}\n",
        "do_not_overwrite_results = True #@param {type:\"boolean\"}\n",
        "zip_results = False #@param {type:\"boolean\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxKxEbTsxIBu"
      },
      "outputs": [],
      "source": [
        "#@title Input protein sequence(s), then hit `Runtime` -> `Run all`\n",
        "from google.colab import files\n",
        "import os\n",
        "import re\n",
        "import hashlib\n",
        "import random\n",
        "\n",
        "from sys import version_info\n",
        "python_version = f\"{version_info.major}.{version_info.minor}\"\n",
        "\n",
        "def add_hash(x,y):\n",
        "  return x+\"_\"+hashlib.sha1(y.encode()).hexdigest()[:5]\n",
        "\n",
        "query_sequence = 'PIAQIHILEGRSDEQKETLIREVSEAISRSLDAPLTSVRVIITEMAKGHFGIGGELASK'\n",
        "jobname = 'initialtest'\n",
        "# number of models to use\n",
        "num_relax = 0\n",
        "template_mode = \"none\"\n",
        "use_amber = num_relax > 0\n",
        "\n",
        "# remove whitespaces\n",
        "query_sequence = \"\".join(query_sequence.split())\n",
        "\n",
        "basejobname = \"\".join(jobname.split())\n",
        "basejobname = re.sub(r'\\W+', '', basejobname)\n",
        "jobname = add_hash(basejobname, query_sequence)\n",
        "\n",
        "# check if directory with jobname exists\n",
        "def check(folder):\n",
        "  if os.path.exists(folder):\n",
        "    return False\n",
        "  else:\n",
        "    return True\n",
        "if not check(jobname):\n",
        "  n = 0\n",
        "  while not check(f\"{jobname}_{n}\"): n += 1\n",
        "  jobname = f\"{jobname}_{n}\"\n",
        "\n",
        "# make directory to save results\n",
        "os.makedirs(jobname, exist_ok=True)\n",
        "\n",
        "# save queries\n",
        "queries_path = os.path.join(jobname, f\"{jobname}.csv\")\n",
        "with open(queries_path, \"w\") as text_file:\n",
        "  text_file.write(f\"id,sequence\\n{jobname},{query_sequence}\")\n",
        "\n",
        "if template_mode == \"pdb100\":\n",
        "  use_templates = True\n",
        "  custom_template_path = None\n",
        "elif template_mode == \"custom\":\n",
        "  custom_template_path = os.path.join(jobname,f\"template\")\n",
        "  os.makedirs(custom_template_path, exist_ok=True)\n",
        "  uploaded = files.upload()\n",
        "  use_templates = True\n",
        "  for fn in uploaded.keys():\n",
        "    os.rename(fn,os.path.join(custom_template_path,fn))\n",
        "else:\n",
        "  custom_template_path = None\n",
        "  use_templates = False\n",
        "\n",
        "print(\"jobname\",jobname)\n",
        "print(\"sequence\",query_sequence)\n",
        "print(\"length\",len(query_sequence.replace(\":\",\"\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iccGdbe_Pmt9"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "%%time\n",
        "import os\n",
        "USE_AMBER = use_amber\n",
        "USE_TEMPLATES = use_templates\n",
        "PYTHON_VERSION = python_version\n",
        "\n",
        "if not os.path.isfile(\"COLABFOLD_READY\"):\n",
        "  print(\"installing colabfold...\")\n",
        "  os.system(\"pip install -q --no-warn-conflicts 'colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold'\")\n",
        "  if os.environ.get('TPU_NAME', False) != False:\n",
        "    os.system(\"pip uninstall -y jax jaxlib\")\n",
        "    os.system(\"pip install --no-warn-conflicts --upgrade dm-haiku==0.0.10 'jax[cuda12_pip]'==0.3.25 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\")\n",
        "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabfold colabfold\")\n",
        "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/alphafold alphafold\")\n",
        "  os.system(\"touch COLABFOLD_READY\")\n",
        "\n",
        "if USE_AMBER or USE_TEMPLATES:\n",
        "  if not os.path.isfile(\"CONDA_READY\"):\n",
        "    print(\"installing conda...\")\n",
        "    os.system(\"wget -qnc https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh\")\n",
        "    os.system(\"bash Miniforge3-Linux-x86_64.sh -bfp /usr/local\")\n",
        "    os.system(\"mamba config --set auto_update_conda false\")\n",
        "    os.system(\"touch CONDA_READY\")\n",
        "\n",
        "if USE_TEMPLATES and not os.path.isfile(\"HH_READY\") and USE_AMBER and not os.path.isfile(\"AMBER_READY\"):\n",
        "  print(\"installing hhsuite and amber...\")\n",
        "  os.system(f\"mamba install -y -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 openmm=8.2.0 python='{PYTHON_VERSION}' pdbfixer\")\n",
        "  os.system(\"touch HH_READY\")\n",
        "  os.system(\"touch AMBER_READY\")\n",
        "else:\n",
        "  if USE_TEMPLATES and not os.path.isfile(\"HH_READY\"):\n",
        "    print(\"installing hhsuite...\")\n",
        "    os.system(f\"mamba install -y -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 python='{PYTHON_VERSION}'\")\n",
        "    os.system(\"touch HH_READY\")\n",
        "  if USE_AMBER and not os.path.isfile(\"AMBER_READY\"):\n",
        "    print(\"installing amber...\")\n",
        "    os.system(f\"mamba install -y -c conda-forge openmm=8.2.0 python='{PYTHON_VERSION}' pdbfixer\")\n",
        "    os.system(\"touch AMBER_READY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F879ICTKFHQZ"
      },
      "outputs": [],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!conda install -c conda-forge pdbfixer -y\n",
        "!pip show pdbfixer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVAma0LC32ex"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmSsLenL8CVY"
      },
      "outputs": [],
      "source": [
        "from colabfold.download import download_alphafold_params\n",
        "download_alphafold_params(model_type=f\"alphafold2_multimer_v3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BipQH6MDGr8N"
      },
      "outputs": [],
      "source": [
        "#@title Run ColabFold Batch with Seed Control\n",
        "\n",
        "from colabfold.batch import get_queries, run\n",
        "from colabfold.download import default_data_dir\n",
        "from colabfold.utils import setup_logging\n",
        "\n",
        "# Add missing import\n",
        "import io\n",
        "import contextlib\n",
        "from pathlib import Path\n",
        "\n",
        "from colabfold.batch import get_queries, run\n",
        "from colabfold.download import default_data_dir\n",
        "from colabfold.utils import setup_logging\n",
        "\n",
        "# Seed configuration\n",
        "SEED = 4  #@param {type:\"integer\"}\n",
        "#@markdown Change SEED value (0, 1, 2, etc.) for different runs\n",
        "\n",
        "# Set all random seeds\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "os.environ['JAX_RANDOM_SEED'] = str(SEED)\n",
        "\n",
        "print(f\"Running with SEED = {SEED}\")\n",
        "\n",
        "setup_logging(Path(result_dir) / \"colabfold_global_log.txt\")\n",
        "\n",
        "#@title Generate FASTA Files and Create Jobs List\n",
        "#@title Define Input/Output Directories and Parameters\n",
        "\n",
        "# Directory configuration\n",
        "input_dir = '/content/input_fasta' #@param {type:\"string\"}\n",
        "result_dir = '/content/results' #@param {type:\"string\"}\n",
        "\n",
        "# Analysis parameters\n",
        "confidence_metric = \"combined\" #@param [\"ipTM\", \"pTM\", \"combined\"]\n",
        "binding_threshold = 0.7 #@param {type:\"number\"}\n",
        "\n",
        "# ColabFold parameters (from your original notebook)\n",
        "msa_mode = \"MMseqs2 (UniRef+Environmental)\" #@param [\"MMseqs2 (UniRef+Environmental)\", \"MMseqs2 (UniRef only)\",\"single_sequence\",\"custom\"]\n",
        "num_models = 5 #@param [1,2,3,4,5] {type:\"raw\"}\n",
        "num_recycles = 48 #@param [1,3,6,12,24,48] {type:\"raw\"}\n",
        "stop_at_score = 80 #@param {type:\"number\"}\n",
        "use_templates = False #@param {type:\"boolean\"}\n",
        "num_relax = 5 #@param [0, 1, 5] {type:\"raw\"}\n",
        "use_amber = num_relax > 0\n",
        "\n",
        "print(f\"Input directory: {input_dir}\")\n",
        "print(f\"Result directory: {result_dir}\")\n",
        "\n",
        "os.makedirs(input_dir, exist_ok=True)\n",
        "os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "# Create all combinations\n",
        "jobs = []\n",
        "for nb_name, nb_info in nanobody_data.items():\n",
        "    for ag_name, ag_info in antigen_data.items():\n",
        "        job_id = f\"{nb_name}_{ag_name}\"\n",
        "        fasta_path = Path(input_dir) / f\"{job_id}.fasta\"\n",
        "\n",
        "        # Write FASTA\n",
        "        with open(fasta_path, 'w') as f:\n",
        "            f.write(f\">{job_id}\\n\")\n",
        "            f.write(f\"{nb_info['sequence']}:{ag_info['sequence']}\\n\")\n",
        "\n",
        "        jobs.append({\n",
        "            'id': job_id,\n",
        "            'nanobody': nb_name,\n",
        "            'antigen': ag_name,\n",
        "            'fasta': str(fasta_path)\n",
        "        })\n",
        "\n",
        "print(f\"Created {len(jobs)} FASTA files\")\n",
        "print(f\"Jobs created: {len(jobs)}\")\n",
        "print(f\"First job: {jobs[0]['id']}\")\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_metrics_from_stdout(log_output):\n",
        "    \"\"\"Extract ipTM, pTM, pLDDT from ColabFold's printed output\"\"\"\n",
        "    match = re.search(r\"rank_001_.*?pLDDT=([[\\d.]+)\\s+pTM=([[\\d.]+)\\s+ipTM=([[\\d.]+)\", log_output)\n",
        "    if match:\n",
        "        plddt, ptm, iptm = map(float, match.groups())\n",
        "        return {\n",
        "            \"mean_plddt\": plddt,\n",
        "            \"max_ptm\": ptm,\n",
        "            \"max_iptm\": iptm\n",
        "        }\n",
        "    print(\"No score line found in stdout.\")\n",
        "    return {\n",
        "        \"mean_plddt\": 0,\n",
        "        \"max_ptm\": 0,\n",
        "        \"max_iptm\": 0\n",
        "    }\n",
        "\n",
        "def get_binding_score(metrics, method='combined'):\n",
        "    \"\"\"Calculate binding score based on selected method\"\"\"\n",
        "    if method == 'ipTM':\n",
        "        return metrics.get('max_iptm', 0)\n",
        "    elif method == 'pTM':\n",
        "        return metrics.get('max_ptm', 0)\n",
        "    elif method == 'combined':\n",
        "        return (0.6 * metrics.get('max_iptm', 0) +\n",
        "                0.3 * metrics.get('max_ptm', 0) +\n",
        "                0.1 * metrics.get('mean_plddt', 0) / 100)\n",
        "    return 0\n",
        "\n",
        "# Run jobs\n",
        "results = []\n",
        "\n",
        "for job in jobs:\n",
        "    print(f\"\\nProcessing {job['id']}...\")\n",
        "    job_dir = Path(result_dir) / job['id']\n",
        "    job_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        queries, is_complex = get_queries(job['fasta'])\n",
        "\n",
        "        buffer = io.StringIO()\n",
        "        with contextlib.redirect_stdout(buffer):\n",
        "            run(\n",
        "                queries=queries,\n",
        "                result_dir=str(job_dir),\n",
        "                use_templates=use_templates,\n",
        "                num_relax=num_relax,\n",
        "                msa_mode=msa_mode,\n",
        "                model_type=\"alphafold2_multimer_v3\",\n",
        "                num_models=num_models,\n",
        "                num_recycles=num_recycles,\n",
        "                is_complex=is_complex,\n",
        "                data_dir=default_data_dir,\n",
        "                rank_by=\"auto\",\n",
        "                stop_at_score=stop_at_score,\n",
        "                zip_results=False\n",
        "            )\n",
        "        log_output = buffer.getvalue()\n",
        "\n",
        "        # Parse from stdout\n",
        "        metrics = extract_metrics_from_stdout(log_output)\n",
        "        print(\"Parsed metrics:\", metrics)\n",
        "\n",
        "        score = get_binding_score(metrics, confidence_metric)\n",
        "        print(\"Binding score:\", score)\n",
        "\n",
        "        results.append({\n",
        "            'nanobody': job['nanobody'],\n",
        "            'antigen': job['antigen'],\n",
        "            'score': score,\n",
        "            'seed': SEED,  # Add seed to results\n",
        "            **metrics\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error running job {job['id']}: {e}\")\n",
        "        results.append({\n",
        "            'nanobody': job['nanobody'],\n",
        "            'antigen': job['antigen'],\n",
        "            'score': 0,\n",
        "            'seed': SEED  # Add seed to results\n",
        "        })\n",
        "\n",
        "# Save results with seed in filename\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(Path(result_dir) / f'results_seed{SEED}.csv', index=False)\n",
        "\n",
        "# Continue with original visualization (unchanged)\n",
        "nanobody_order = list(nanobody_data.keys())\n",
        "antigen_order = list(antigen_data.keys())\n",
        "matrix = df.pivot(index='nanobody', columns='antigen', values='score').reindex(index=nanobody_order, columns=antigen_order)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 8))\n",
        "ax = sns.heatmap(\n",
        "    matrix,\n",
        "    annot=True,\n",
        "    fmt='.3f',\n",
        "    cmap=sns.color_palette(\"viridis\", as_cmap=True),\n",
        "    vmin=0,\n",
        "    vmax=1,\n",
        "    square=True,\n",
        "    linewidths=0.5,\n",
        "    cbar_kws={'label': f'Binding Score ({confidence_metric}) - Seed {SEED}'}\n",
        ")\n",
        "\n",
        "# Highlight high scores\n",
        "for i, nb in enumerate(matrix.index):\n",
        "    for j, ag in enumerate(matrix.columns):\n",
        "        if matrix.loc[nb, ag] > binding_threshold:\n",
        "            ax.add_patch(plt.Rectangle((j, i), 1, 1, fill=False, edgecolor='red', lw=3))\n",
        "\n",
        "plt.title(f'Nanobody-Antigen Binding Matrix - Seed {SEED}', fontsize=14, pad=15)\n",
        "plt.tight_layout()\n",
        "plt.savefig(Path(result_dir) / f'binding_matrix_seed{SEED}.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\nTop Binding Pairs:\")\n",
        "df_sorted = df.sort_values('score', ascending=False)\n",
        "for _, row in df_sorted.head(5).iterrows():\n",
        "    print(f\"  {row['nanobody']} + {row['antigen']}: {row['score']:.3f}\")\n",
        "\n",
        "# Save results with seed identifier\n",
        "matrix.to_csv(Path(result_dir) / f'matrix_seed{SEED}.csv')\n",
        "\n",
        "print(f\"\\nResults saved to {result_dir} with seed {SEED}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1hgUMU3UKq7"
      },
      "outputs": [],
      "source": [
        "#@title Aggregate Results from Multiple Seeds (Run after all seeds complete)\n",
        "\n",
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# Find all seed result directories\n",
        "seed_dirs = glob.glob(f\"{result_dir}_seed*\")\n",
        "print(f\"Found {len(seed_dirs)} seed directories\")\n",
        "\n",
        "# Collect all results\n",
        "all_seed_results = []\n",
        "for seed_dir in sorted(seed_dirs):\n",
        "    seed_num = int(seed_dir.split('_seed')[-1])\n",
        "    csv_path = Path(seed_dir) / f'results_seed{seed_num}.csv'\n",
        "\n",
        "    if csv_path.exists():\n",
        "        df_seed = pd.read_csv(csv_path)\n",
        "        all_seed_results.append(df_seed)\n",
        "        print(f\"Loaded seed {seed_num}: {len(df_seed)} results\")\n",
        "\n",
        "if all_seed_results:\n",
        "    # Combine all results\n",
        "    df_all = pd.concat(all_seed_results, ignore_index=True)\n",
        "\n",
        "    # Calculate statistics\n",
        "    df_stats = df_all.groupby(['nanobody', 'antigen'])['score'].agg([\n",
        "        'mean', 'std', 'min', 'max', 'count'\n",
        "    ]).reset_index()\n",
        "\n",
        "    # Create mean matrix\n",
        "    mean_matrix = df_stats.pivot(\n",
        "        index='nanobody',\n",
        "        columns='antigen',\n",
        "        values='mean'\n",
        "    ).reindex(\n",
        "        index=list(nanobody_data.keys()),\n",
        "        columns=list(antigen_data.keys())\n",
        "    )\n",
        "\n",
        "    # Create std matrix\n",
        "    std_matrix = df_stats.pivot(\n",
        "        index='nanobody',\n",
        "        columns='antigen',\n",
        "        values='std'\n",
        "    ).reindex(\n",
        "        index=list(nanobody_data.keys()),\n",
        "        columns=list(antigen_data.keys())\n",
        "    )\n",
        "\n",
        "    # Visualization\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "\n",
        "    # Mean scores\n",
        "    sns.heatmap(\n",
        "        mean_matrix,\n",
        "        annot=True,\n",
        "        fmt='.3f',\n",
        "        cmap='viridis',\n",
        "        vmin=0,\n",
        "        vmax=1,\n",
        "        square=True,\n",
        "        linewidths=0.5,\n",
        "        cbar_kws={'label': 'Mean Binding Score'},\n",
        "        ax=ax1\n",
        "    )\n",
        "    ax1.set_title(f'Mean Binding Scores (n={len(all_seed_results)} seeds)', fontsize=14)\n",
        "\n",
        "    # Highlight reliable predictions\n",
        "    for i, nb in enumerate(mean_matrix.index):\n",
        "        for j, ag in enumerate(mean_matrix.columns):\n",
        "            if mean_matrix.loc[nb, ag] > 0.7 and std_matrix.loc[nb, ag] < 0.05:\n",
        "                ax1.add_patch(plt.Rectangle((j, i), 1, 1, fill=False, edgecolor='red', lw=3))\n",
        "\n",
        "    # Standard deviations\n",
        "    sns.heatmap(\n",
        "        std_matrix,\n",
        "        annot=True,\n",
        "        fmt='.3f',\n",
        "        cmap='Reds',\n",
        "        vmin=0,\n",
        "        vmax=0.2,\n",
        "        square=True,\n",
        "        linewidths=0.5,\n",
        "        cbar_kws={'label': 'Standard Deviation'},\n",
        "        ax=ax2\n",
        "    )\n",
        "    ax2.set_title('Score Standard Deviation', fontsize=14)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{result_dir}_aggregated/binding_matrix_aggregated.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # Save aggregated results\n",
        "    os.makedirs(f'{result_dir}_aggregated', exist_ok=True)\n",
        "    df_all.to_csv(f'{result_dir}_aggregated/all_seeds_results.csv', index=False)\n",
        "    df_stats.to_csv(f'{result_dir}_aggregated/statistics.csv', index=False)\n",
        "    mean_matrix.to_csv(f'{result_dir}_aggregated/mean_matrix.csv')\n",
        "    std_matrix.to_csv(f'{result_dir}_aggregated/std_matrix.csv')\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\nTop Reliable Binding Pairs:\")\n",
        "    reliable = df_stats[\n",
        "        (df_stats['mean'] > 0.7) &\n",
        "        (df_stats['std'] < 0.05)\n",
        "    ].sort_values('mean', ascending=False)\n",
        "\n",
        "    for _, row in reliable.iterrows():\n",
        "        print(f\"  {row['nanobody']} + {row['antigen']}: {row['mean']:.3f} ¬± {row['std']:.3f}\")\n",
        "else:\n",
        "    print(\"No seed results found!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lpj22VbHQ_dc"
      },
      "outputs": [],
      "source": [
        "#@title Create Visualization\n",
        "# Preliminary plot\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"results\", results)\n",
        "# Create matrix\n",
        "df = pd.DataFrame(results)\n",
        "nanobody_order = list(nanobody_data.keys())\n",
        "antigen_order = list(antigen_data.keys())\n",
        "matrix = df.pivot(index='nanobody', columns='antigen', values='score').reindex(index=nanobody_order, columns=antigen_order)\n",
        "\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 8))\n",
        "ax = sns.heatmap(\n",
        "    matrix,\n",
        "    annot=True,\n",
        "    fmt='.3f',\n",
        "    cmap=sns.color_palette(\"viridis\", as_cmap=True),\n",
        "    vmin=0,\n",
        "    vmax=1,\n",
        "    square=True,\n",
        "    linewidths=0.5,\n",
        "    cbar_kws={'label': f'Binding Score ({confidence_metric})'}\n",
        ")\n",
        "binding_threshold = 1.0\n",
        "# Highlight high scores\n",
        "for i, nb in enumerate(matrix.index):\n",
        "    for j, ag in enumerate(matrix.columns):\n",
        "        if matrix.loc[nb, ag] > binding_threshold:\n",
        "            ax.add_patch(plt.Rectangle((j, i), 1, 1, fill=False, edgecolor='red', lw=3))\n",
        "\n",
        "plt.title('Nanobody-Antigen Binding Matrix', fontsize=14, pad=15)\n",
        "plt.tight_layout()\n",
        "plt.savefig(Path(result_dir) / 'binding_matrix.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\nTop Binding Pairs:\")\n",
        "df_sorted = df.sort_values('score', ascending=False)\n",
        "for _, row in df_sorted.head(5).iterrows():\n",
        "    print(f\"  {row['nanobody']} + {row['antigen']}: {row['score']:.3f}\")\n",
        "\n",
        "# Save results\n",
        "df.to_csv(Path(result_dir) / 'results.csv', index=False)\n",
        "matrix.to_csv(Path(result_dir) / 'matrix.csv')\n",
        "\n",
        "print(f\"\\nResults saved to {result_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGUBLzB3C6WN"
      },
      "source": [
        "# Instructions <a name=\"Instructions\"></a>\n",
        "**Quick start**\n",
        "1. Upload your single fasta files to a folder in your Google Drive\n",
        "2. Define path to the fold containing the fasta files (`input_dir`) define an outdir (`output_dir`)\n",
        "3. Press \"Runtime\" -> \"Run all\".\n",
        "\n",
        "**Result zip file contents**\n",
        "\n",
        "At the end of the job a all results `jobname.result.zip` will be uploaded to your (`output_dir`) Google Drive. Each zip contains one protein.\n",
        "\n",
        "1. PDB formatted structures sorted by avg. pIDDT. (unrelaxed and relaxed if `use_amber` is enabled).\n",
        "2. Plots of the model quality.\n",
        "3. Plots of the MSA coverage.\n",
        "4. Parameter log file.\n",
        "5. A3M formatted input MSA.\n",
        "6. BibTeX file with citations for all used tools and databases.\n",
        "\n",
        "\n",
        "**Troubleshooting**\n",
        "* Check that the runtime type is set to GPU at \"Runtime\" -> \"Change runtime type\".\n",
        "* Try to restart the session \"Runtime\" -> \"Factory reset runtime\".\n",
        "* Check your input sequence.\n",
        "\n",
        "**Known issues**\n",
        "* Google Colab assigns different types of GPUs with varying amount of memory. Some might not have enough memory to predict the structure for a long sequence.\n",
        "* Google Colab assigns different types of GPUs with varying amount of memory. Some might not have enough memory to predict the structure for a long sequence.\n",
        "* Your browser can block the pop-up for downloading the result file. You can choose the `save_to_google_drive` option to upload to Google Drive instead or manually download the result file: Click on the little folder icon to the left, navigate to file: `jobname.result.zip`, right-click and select \\\"Download\\\" (see [screenshot](https://pbs.twimg.com/media/E6wRW2lWUAEOuoe?format=jpg&name=small)).\n",
        "\n",
        "**Limitations**\n",
        "* Computing resources: Our MMseqs2 API can handle ~20-50k requests per day.\n",
        "* MSAs: MMseqs2 is very precise and sensitive but might find less hits compared to HHblits/HMMer searched against BFD or Mgnify.\n",
        "* We recommend to additionally use the full [AlphaFold2 pipeline](https://github.com/deepmind/alphafold).\n",
        "\n",
        "**Description of the plots**\n",
        "*   **Number of sequences per position** - We want to see at least 30 sequences per position, for best performance, ideally 100 sequences.\n",
        "*   **Predicted lDDT per position** - model confidence (out of 100) at each position. The higher the better.\n",
        "*   **Predicted Alignment Error** - For homooligomers, this could be a useful metric to assess how confident the model is about the interface. The lower the better.\n",
        "\n",
        "**Bugs**\n",
        "- If you encounter any bugs, please report the issue to https://github.com/sokrypton/ColabFold/issues\n",
        "\n",
        "**License**\n",
        "\n",
        "The source code of ColabFold is licensed under [MIT](https://raw.githubusercontent.com/sokrypton/ColabFold/main/LICENSE). Additionally, this notebook uses AlphaFold2 source code and its parameters licensed under [Apache 2.0](https://raw.githubusercontent.com/deepmind/alphafold/main/LICENSE) and  [CC BY 4.0](https://creativecommons.org/licenses/by-sa/4.0/) respectively. Read more about the AlphaFold license [here](https://github.com/deepmind/alphafold).\n",
        "\n",
        "**Acknowledgments**\n",
        "- We thank the AlphaFold team for developing an excellent model and open sourcing the software.\n",
        "\n",
        "- Do-Yoon Kim for creating the ColabFold logo.\n",
        "\n",
        "- A colab by Sergey Ovchinnikov ([@sokrypton](https://twitter.com/sokrypton)), Milot Mirdita ([@milot_mirdita](https://twitter.com/milot_mirdita)) and Martin Steinegger ([@thesteinegger](https://twitter.com/thesteinegger)).\n",
        "\n",
        "- Slightly modified to accomodate a binding specificity evaluation experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RjnwsWQNz1H"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}